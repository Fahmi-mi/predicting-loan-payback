{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exploratory Data Analysis\n",
        "# Only run once\n",
        "import sys\n",
        "import os\n",
        "\n",
        "project_root = os.path.abspath('../')\n",
        "os.chdir(project_root)\n",
        "\n",
        "src_path = os.path.abspath(os.path.join(os.getcwd(), 'src'))\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98661dbf",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fc71d02",
      "metadata": {},
      "outputs": [],
      "source": [
        "from load_data import DataLoader\n",
        "from preprocess import Preprocessor, FeatureEngineering\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "dl = DataLoader()\n",
        "pre = Preprocessor()\n",
        "fe = FeatureEngineering()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "184fcb06",
      "metadata": {},
      "outputs": [],
      "source": [
        "train = dl.load_data('', 'data/raw')\n",
        "test = dl.load_data('', 'data/raw')\n",
        "\n",
        "# train_clean = dl.load_data('train_clean.csv', 'data/processed')\n",
        "# test_clean = dl.load_data('test_clean.csv', 'data/processed')\n",
        "\n",
        "train_df = train.copy()\n",
        "test_df = test.copy()\n",
        "\n",
        "# train_df = train_clean.copy()\n",
        "# test_df = test_clean.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0100205",
      "metadata": {},
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d504a97c",
      "metadata": {},
      "source": [
        "## Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948018f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "dl.data_info(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c601d5c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "dl.preview_data(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "243fbfdc",
      "metadata": {},
      "outputs": [],
      "source": [
        "dl.data_info(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6672fa77",
      "metadata": {},
      "outputs": [],
      "source": [
        "dl.preview_data(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14d70b20",
      "metadata": {},
      "source": [
        "## Cleaning and validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7f5f15f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_and_clean_data(df, name=\"data\", is_test=False):\n",
        "    print(f\"=== Data Validation and Cleaning for {name} ===\")\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    skip_cols = ['id']\n",
        "    if not is_test:\n",
        "        skip_cols.append('accident_risk')\n",
        "    \n",
        "    print(\"\\n1. Checking numeric columns for non-numeric values:\")\n",
        "    numeric_cols = df_clean.select_dtypes(include=['int64', 'float64']).columns\n",
        "    \n",
        "    for col in numeric_cols:\n",
        "        if col in skip_cols:\n",
        "            continue\n",
        "\n",
        "        str_values = df_clean[col].astype(str)\n",
        "        non_numeric_mask = ~str_values.str.match(r'^-?\\d*\\.?\\d*$')\n",
        "        non_numeric_count = non_numeric_mask.sum()\n",
        "\n",
        "        if non_numeric_count > 0:\n",
        "            print(f\"  - {col}: Found {non_numeric_count} non-numeric values\")\n",
        "            print(f\"    Sample values: {df_clean[col][non_numeric_mask].unique()[:5]}\")\n",
        "\n",
        "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
        "    \n",
        "    print(\"\\n2. Checking categorical columns for data type issues:\")\n",
        "    categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
        "    \n",
        "    for col in categorical_cols:\n",
        "        unique_vals = df_clean[col].unique()\n",
        "        print(f\"  - {col}: {len(unique_vals)} unique values\")\n",
        "        print(f\"    Sample values: {unique_vals[:5]}\")\n",
        "        \n",
        "        if len(unique_vals) > 50:\n",
        "            try:\n",
        "                numeric_test = pd.to_numeric(df_clean[col], errors='coerce')\n",
        "                if numeric_test.notna().sum() / len(df_clean) > 0.8:\n",
        "                    print(f\"    WARNING: {col} might be numeric but stored as object\")\n",
        "                    print(f\"    Consider converting to numeric type\")\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    print(\"\\n3. Checking for constant columns:\")\n",
        "    constant_cols = [col for col in df_clean.columns if df_clean[col].nunique() <= 1]\n",
        "    if constant_cols:\n",
        "        print(f\"  Found {len(constant_cols)} constant columns:\")\n",
        "        for col in constant_cols:\n",
        "            print(f\"    - {col}: {df_clean[col].iloc[0] if len(df_clean) > 0 else 'Empty'}\")\n",
        "    else:\n",
        "        print(\"  No constant columns found\")\n",
        "    \n",
        "    print(\"\\n4. Checking for duplicate columns:\")\n",
        "    duplicate_cols = []\n",
        "    for i, col1 in enumerate(df_clean.columns):\n",
        "        for col2 in df_clean.columns[i+1:]:\n",
        "            if df_clean[col1].equals(df_clean[col2]):\n",
        "                duplicate_cols.append((col1, col2))\n",
        "    \n",
        "    if duplicate_cols:\n",
        "        print(f\"  Found {len(duplicate_cols)} duplicate column pairs:\")\n",
        "        for col1, col2 in duplicate_cols:\n",
        "            print(f\"    - {col1} == {col2}\")\n",
        "    else:\n",
        "        print(\"  No duplicate columns found\")\n",
        "    \n",
        "    print(f\"\\n5. Data types summary after cleaning:\")\n",
        "    print(f\"  - Numeric columns: {len(df_clean.select_dtypes(include=['int64', 'float64']).columns)}\")\n",
        "    print(f\"  - Categorical columns: {len(df_clean.select_dtypes(include=['object', 'category']).columns)}\")\n",
        "    print(f\"  - Other types: {len(df_clean.select_dtypes(exclude=['int64', 'float64', 'object', 'category']).columns)}\")\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "train_clean = validate_and_clean_data(train_df, \"train\")\n",
        "test_clean = validate_and_clean_data(test_df, \"test\", is_test=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e40d649",
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_column_definitions(df, is_test=False):\n",
        "    cols_to_drop = ['id']\n",
        "    if not is_test:\n",
        "        cols_to_drop.append('accident_risk')\n",
        "    \n",
        "    available_cols = [col for col in cols_to_drop if col in df.columns]\n",
        "    df_features = df.drop(columns=available_cols)\n",
        "    \n",
        "    num_cols_updated = df_features.select_dtypes(include=['float64', 'int64']).columns\n",
        "    cat_cols_updated = df_features.select_dtypes(include=['object', 'category']).columns\n",
        "    \n",
        "    print(\"Updated column definitions:\")\n",
        "    print(f\"Numerical columns ({len(num_cols_updated)}): {list(num_cols_updated)}\")\n",
        "    print(f\"Categorical columns ({len(cat_cols_updated)}): {list(cat_cols_updated)}\")\n",
        "    \n",
        "    return num_cols_updated, cat_cols_updated\n",
        "\n",
        "num_cols_clean, cat_cols_clean = update_column_definitions(train_clean, is_test=False)\n",
        "num_cols_test, cat_cols_test = update_column_definitions(test_clean, is_test=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "963413c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fix_data_types(df):\n",
        "    df_fixed = df.copy()\n",
        "    \n",
        "    for col in df_fixed.select_dtypes(include=['int64', 'float64']).columns:\n",
        "        if col in ['id', 'accident_risk']:\n",
        "            continue\n",
        "        \n",
        "        df_fixed[col] = pd.to_numeric(df_fixed[col], errors='coerce')\n",
        "        \n",
        "        if df_fixed[col].isna().sum() > df[col].isna().sum():\n",
        "            print(f\"Fixed non-numeric values in column '{col}'\")\n",
        "    \n",
        "    return df_fixed\n",
        "\n",
        "print(\"Checking and fixing data type issues...\")\n",
        "train_df = fix_data_types(train_df)\n",
        "test_df = fix_data_types(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ee9a0d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_clean.to_csv('data/processed/train_clean.csv', index=False)\n",
        "test_clean.to_csv('data/processed/test_clean.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68b6c2f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = train_df.drop(columns=['id', 'target']).select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols = train_df.drop(columns=['id', 'target']).select_dtypes(include=['object', 'category', 'bool']).columns\n",
        "num_cols_test = test_df.drop(columns=['id']).select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols_test = test_df.drop(columns=['id']).select_dtypes(include=['object', 'category', 'bool']).columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99e64388",
      "metadata": {},
      "source": [
        "## Missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "956dc628",
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_missing(df, name=\"data\"):\n",
        "    missing = df.isnull().sum()\n",
        "    missing = missing[missing > 0].sort_values(ascending=False)\n",
        "    if not missing.empty:\n",
        "        print(f\"Missing values in {name}:\")\n",
        "        display(missing)\n",
        "        missing.plot(kind='bar', title=f'Missing Values in {name}')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No missing values found in {name}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6723937",
      "metadata": {},
      "outputs": [],
      "source": [
        "show_missing(train_df, \"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "047b484d",
      "metadata": {},
      "source": [
        "## Data distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f01c77ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(num_cols) > 0:\n",
        "    n_cols = 2\n",
        "    n_rows = -(-len(num_cols) // n_cols)\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4 * n_rows))\n",
        "    if n_rows == 1 and len(num_cols) == 1:\n",
        "        axes = [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(num_cols):\n",
        "        sns.histplot(train_df, x=col, kde=True, bins=30, ax=axes[i])\n",
        "        axes[i].set_title(f'Distribution of {col}')\n",
        "        axes[i].set_xlabel(col)\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "\n",
        "    for i in range(len(num_cols), len(axes)):\n",
        "        fig.delaxes(axes[i])\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No numerical columns found in the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "868ab818",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(cat_cols) > 0:\n",
        "    n_cols = 2\n",
        "    n_rows = -(-len(cat_cols) // n_cols)\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4 * n_rows))\n",
        "    if n_rows == 1 and len(cat_cols) == 1:\n",
        "        axes = [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(cat_cols):\n",
        "        sns.countplot(train_df, x=col, ax=axes[i])\n",
        "        axes[i].set_title(f'Distribution of {col}')\n",
        "        axes[i].set_xlabel(col)\n",
        "        # axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45, ha='right')\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "\n",
        "    for i in range(len(cat_cols), len(axes)):\n",
        "        fig.delaxes(axes[i])\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No categorical columns found in the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c178288",
      "metadata": {},
      "source": [
        "## Outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85940e77",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(num_cols) > 0:\n",
        "    n_cols = 2\n",
        "    n_rows = -(-len(num_cols) // n_cols)\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4 * n_rows))\n",
        "    if n_rows == 1 and len(num_cols) == 1:\n",
        "        axes = [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(num_cols):\n",
        "        sns.boxplot(train_df, y=col, ax=axes[i])\n",
        "        axes[i].set_title(f'Boxplot of {col}')\n",
        "        axes[i].set_ylabel(col)\n",
        "        \n",
        "    for i in range(len(num_cols), len(axes)):\n",
        "        fig.delaxes(axes[i])\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No numerical columns found in the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42149d44",
      "metadata": {},
      "source": [
        "## Feature-target relationship analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8169bc72",
      "metadata": {},
      "source": [
        "### Numerical and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1857f178",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(num_cols) > 0:\n",
        "    n_cols = 2\n",
        "    n_rows = -(-len(num_cols) // n_cols)\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4 * n_rows))\n",
        "    if n_rows == 1 and len(num_cols) == 1:\n",
        "        axes = [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(num_cols):\n",
        "        sns.violinplot(train_df, x='target', y=col, ax=axes[i])\n",
        "        axes[i].set_title(f'Violin plot of {col} by target')\n",
        "        axes[i].set_xlabel('Target')\n",
        "        axes[i].set_ylabel(col)\n",
        "        \n",
        "    for i in range(len(num_cols), len(axes)):\n",
        "        fig.delaxes(axes[i])\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No numerical columns found for violin plot analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d0c2b4",
      "metadata": {},
      "source": [
        "### Categorical and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "281ec6d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(cat_cols) > 0:\n",
        "    for col in cat_cols:\n",
        "        ct = pd.crosstab(train_df[col], train_df['target'], normalize='index')\n",
        "        ct.plot(kind='bar', stacked=True, figsize=(6, 4))\n",
        "        plt.title(f'Proportion of target by {col}')\n",
        "        plt.xlabel(col)\n",
        "        plt.ylabel('Proportion')\n",
        "        plt.legend(title='target', loc='upper right')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"No categorical columns to analyze with target.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f329a2c9",
      "metadata": {},
      "source": [
        "## Pairplot matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "325d5022",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(num_cols) > 0:\n",
        "    pairplot_cols = num_cols.tolist() + ['target']\n",
        "    \n",
        "    sns.pairplot(train_df[pairplot_cols], hue='target', diag_kind='kde', palette=\"Set1\", corner=True)\n",
        "    plt.suptitle('Pairplot of Numerical Features with Target', y=1.02)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No numerical columns found for pairplot analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad87a31b",
      "metadata": {},
      "source": [
        "## Multicolinearity analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb858e59",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_to_encode = train_df.copy()\n",
        "train_encoded = pre.label_encode(train_to_encode)\n",
        "train_corr = train_encoded.corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(train_corr, annot=True, fmt='.2f', cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8})\n",
        "plt.title('Correlation Heatmap of Encoded Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07925faa",
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_correlation(corr_matrix, top_n=5):\n",
        "    corr_pairs = (\n",
        "        corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "        .stack()\n",
        "        .reset_index()\n",
        "    )\n",
        "    corr_pairs.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
        "    top_pos = corr_pairs.sort_values(by='Correlation', ascending=False).head(top_n)\n",
        "    top_neg = corr_pairs.sort_values(by='Correlation').head(top_n)\n",
        "    print(\"Top positively correlated feature pairs:\")\n",
        "    display(top_pos)\n",
        "    print(\"\\nTop negatively correlated feature pairs:\")\n",
        "    display(top_neg)\n",
        "\n",
        "analyze_correlation(train_corr, top_n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aac128f",
      "metadata": {},
      "source": [
        "## Skewness and kurtosis analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2b9226a",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(num_cols) > 0:\n",
        "    skew_kurt = pd.DataFrame({\n",
        "        'skew': train_df[num_cols].skew(),\n",
        "        'kurtosis': train_df[num_cols].kurt()\n",
        "    })\n",
        "\n",
        "    display(skew_kurt)\n",
        "\n",
        "    skew_kurt.plot(kind='bar', subplots=True, layout=(2, 1), figsize=(10, 6), title=['Skewness', 'Kurtosis'])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No numerical columns found for skewness and kurtosis analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59feb2ee",
      "metadata": {},
      "source": [
        "## Unique values and category frequency analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ed2e4f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(cat_cols) > 0:\n",
        "    for col in cat_cols:\n",
        "        print(f\"Feature: {col}\")\n",
        "        print(f\"  Unique category count: {train_df[col].nunique()}\")\n",
        "        if train_df[col].nunique() > 0:\n",
        "            top_cat = train_df[col].value_counts().idxmax()\n",
        "            top_freq = train_df[col].value_counts().max()\n",
        "            print(f\"  Most frequent categories: {top_cat} ({top_freq} data)\")\n",
        "        print(\"-\" * 45)\n",
        "else:\n",
        "    print(\"No categorical columns found in the dataset.\")\n",
        "    print(\"All features appear to be numerical.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7341c223",
      "metadata": {},
      "source": [
        "## Constant value analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64be6d41",
      "metadata": {},
      "outputs": [],
      "source": [
        "constant_cols = [col for col in train_df.columns if train_df[col].nunique() == 1]\n",
        "if constant_cols:\n",
        "    print(\"Columns with constant values (only one unique value):\")\n",
        "    for col in constant_cols:\n",
        "        print(f\"- {col}: {train_df[col].unique()[0]}\")\n",
        "else:\n",
        "    print(\"There are no columns with constant values.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.13.0",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
